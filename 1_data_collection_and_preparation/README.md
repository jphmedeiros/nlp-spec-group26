# AnÃ¡lise de ProposiÃ§Ãµes Legislativas da CÃ¢mara dos Deputados (TCC)

Este repositÃ³rio contÃ©m o cÃ³digo-fonte e o pipeline de processamento de dados para a anÃ¡lise de proposiÃ§Ãµes legislativas da CÃ¢mara dos Deputados do Brasil. Este projeto faz parte de um Trabalho de ConclusÃ£o de Curso (TCC) de uma pÃ³s-graduaÃ§Ã£o em Processamento de Linguagem Natural (NLP).

## ğŸ“‚ Estrutura do Projeto

```text
TCC/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/            # Dados originais imutÃ¡veis (JSONs brutos)
â”‚   â”œâ”€â”€ interim/        # Dados intermediÃ¡rios (filtrados e transformados)
â”‚   â””â”€â”€ processed/      # Conjuntos de dados finais (com texto extraÃ­do)
â”œâ”€â”€ src/                # CÃ³digo-fonte
â”‚   â”œâ”€â”€ config.py       # DefiniÃ§Ãµes de caminhos e configuraÃ§Ãµes
â”‚   â”œâ”€â”€ filtrar_dados.py # Script ETL para filtragem e uniÃ£o de dados
â”‚   â””â”€â”€ extrair_texto.py # Script para extraÃ§Ã£o e limpeza de texto de PDFs
â”œâ”€â”€ requirements.txt    # DependÃªncias do Python
â””â”€â”€ README.md           # DocumentaÃ§Ã£o do projeto
```

## ğŸš€ Como ComeÃ§ar

### PrÃ©-requisitos

*   Python 3.12 ou superior
*   Ambiente virtual (recomendado)

### InstalaÃ§Ã£o

1.  Clone o repositÃ³rio:
    ```bash
    git clone https://github.com/SEU_USUARIO/SEU_REPOSITORIO.git
    cd TCC
    ```

2.  Crie e ative um ambiente virtual:
    ```bash
    python -m venv venv
    # Windows:
    .\venv\Scripts\activate
    # Linux/Mac:
    source venv/bin/activate
    ```

3.  Instale as dependÃªncias:
    ```bash
    pip install -r requirements.txt
    ```

## ğŸ› ï¸ Uso

O pipeline consiste em dois scripts principais localizados no diretÃ³rio `src`.

### 1. Filtragem e UniÃ£o de Dados
Filtra as proposiÃ§Ãµes brutas por tipo (PL, PEC, PLP) e data, e mescla as informaÃ§Ãµes dos autores.

```bash
python src/filtrar_dados.py
```
*   **Entrada:** `data/raw/proposicoes-2025.json`, `data/raw/proposicoesAutores-2025.json`
*   **SaÃ­da:** `data/interim/proposicoes-final-completo.json`

### 2. ExtraÃ§Ã£o e Limpeza de Texto
Baixa o PDF do inteiro teor de cada proposiÃ§Ã£o, extrai o texto e realiza a limpeza (remoÃ§Ã£o de cabeÃ§alhos, rodapÃ©s, carimbos, etc.).

```bash
python src/extrair_texto.py
```
*   **Entrada:** `data/interim/proposicoes-final-completo.json`
*   **SaÃ­da:** `data/processed/proposicoes-com-texto-limpo.json`

## âš™ï¸ ConfiguraÃ§Ã£o

VocÃª pode modificar as regras de filtragem (datas, tipos) e os limiares de limpeza diretamente nos scripts ou editando o arquivo `src/config.py` (para caminhos de arquivos).

*   **`src/filtrar_dados.py`**: Edite `START_DATE`, `END_DATE`, `TIPOS_VALIDOS`.
*   **`src/extrair_texto.py`**: Edite `TOP_FRAC`, `REPEAT_THRESHOLD` para ajustar a sensibilidade da limpeza de PDFs.

## ğŸ“Š Fonte de Dados

Os arquivos de dados brutos utilizados neste projeto sÃ£o obtidos atravÃ©s do portal de **Dados Abertos da CÃ¢mara dos Deputados**.

Os arquivos `proposicoes-2025.json` e `proposicoesAutores-2025.json` devem ser baixados na seÃ§Ã£o de arquivos estÃ¡ticos:
*   **URL:** [Dados Abertos - Arquivos EstÃ¡ticos](https://dadosabertos.camara.leg.br/swagger/api.html?tab=staticfile)

## ğŸ“Š Fluxo de Dados

1.  **Dados Brutos**: `data/raw/` deve conter os datasets JSON iniciais baixados da fonte acima.
2.  **ETL**: `filtrar_dados.py` limpa os metadados e une os autores.
3.  **IntermediÃ¡rio**: A lista filtrada Ã© salva em `data/interim/`.
4.  **ExtraÃ§Ã£o**: `extrair_texto.py` baixa os PDFs e extrai o texto.
5.  **Processado**: O JSON final com o texto limpo Ã© salvo em `data/processed/`.

## ğŸ“ LicenÃ§a

[Especificar LicenÃ§a, ex: MIT]