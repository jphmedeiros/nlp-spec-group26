# Projeto de An√°lise de Proposi√ß√µes Legislativas (NLP) - Grupo 26

Este projeto foi desenvolvido para coletar, processar e analisar proposi√ß√µes legislativas da C√¢mara dos Deputados do Brasil. Ele utiliza t√©cnicas de Processamento de Linguagem Natural (NLP) e modelos de linguagem de grande escala (LLMs) para extrair insights autom√°ticos de textos legislativos.

## üèóÔ∏è Estrutura do Projeto

O reposit√≥rio est√° organizado em tr√™s m√≥dulos principais:

### 1. Coleta e Prepara√ß√£o de Dados (`1_data_collection_and_preparation/`)
Pipeline ETL em Python respons√°vel por preparar o dataset inicial.
*   **Fun√ß√£o:** Filtra dados brutos (JSON) da API de Dados Abertos, baixa os PDFs do inteiro teor das proposi√ß√µes e extrai o texto limpo.
*   **Tecnologias:** Python, Requests, PyMuPDF (fitz).

### 2. Backend e Processamento NLP (`2_backend/`)
Aplica√ß√£o Python que realiza a an√°lise inteligente dos dados.
*   **Fun√ß√£o:** Ingest√£o de dados no PostgreSQL, gera√ß√£o de nuvens de palavras e integra√ß√£o com OpenAI para:
    *   Sumariza√ß√£o de textos.
    *   An√°lise de sentimento e ideologia.
    *   Extra√ß√£o de Entidades Nomeadas (NER).
    *   Classifica√ß√£o tem√°tica autom√°tica.
*   **Tecnologias:** Python, PostgreSQL, OpenAI API, Docling, Pydantic.

### 3. Frontend (`3_frontend/`)
Painel de visualiza√ß√£o de dados.
*   **Arquivo:** `nlp-spec-group26.pbix`
*   **Fun√ß√£o:** Dashboard em Power BI para visualiza√ß√£o dos resultados anal√≠ticos gerados pelo backend.

---

## üöÄ Como Executar

### Pr√©-requisitos
*   Python 3.12 ou superior.
*   PostgreSQL instalado e em execu√ß√£o.
*   Chave de API da OpenAI.

### Passo 1: Prepara√ß√£o dos Dados
1.  Acesse a pasta: `cd 1_data_collection_and_preparation`
2.  Instale as depend√™ncias: `pip install -r requirements.txt`
3.  Execute os scripts de filtragem e extra√ß√£o:
    ```bash
    python src/filtrar_dados.py
    python src/extrair_texto.py
    ```

### Passo 2: Backend e An√°lise
1.  Acesse a pasta: `cd 2_backend`
2.  Instale as depend√™ncias: `pip install -r requirements.txt`
3.  Configure as vari√°veis de ambiente:
    *   Renomeie `.env.example` para `.env`.
    *   Preencha as credenciais do banco de dados e sua `OPENAI_API_KEY`.
4.  Crie as tabelas no banco de dados:
    ```bash
    python -m data_extractor.migrations
    ```
5.  Inicie o pipeline de processamento:
    ```bash
    python main.py
    ```

### Passo 3: Visualiza√ß√£o
1.  Abra o arquivo `nlp-spec-group26.pbix` no **Power BI Desktop**.
2.  Atualize as fontes de dados para apontar para o seu banco de dados PostgreSQL.

---

## üõ†Ô∏è Conven√ß√µes de Desenvolvimento

*   **Ambientes Virtuais:** Recomenda-se criar um `venv` independente para cada pasta de c√≥digo (`1_` e `2_`).
*   **Configura√ß√µes:**
    *   Par√¢metros de limpeza de texto e datas est√£o em `1_data_collection_and_preparation/src/config.py`.
    *   Configura√ß√µes de infraestrutura e IA est√£o no `.env` do backend.
